---
title: "Generative AI Will Not Kill Developer Jobs"
date: 2024-09-02T14:49:20+01:00
draft: false
---

Large language models have taken the world by storm. By now, it's pretty clear that they are capable of more than originally expected, both by the public as well as their creators. Software developers in particular have been surprised by how good these LLM-based tools are at writing code, and [even entire applications]({{< relref "ai-developer" >}}). With that success comes the old fear that it will kill jobs. Like any new technology, it raises that question, similar to how cars or computers did when they were invented. Is this time different?

I think the answer is no. My prediction is that AI will actually create *more* software developer jobs than it kills. Those engaging in the fear-mongering misunderstand the fundamental goal of a software developer. Yes, they write code. But code itself is not the final output of a software developer. Every developer has the goal of solving a problem for a user - a customer, or a business partner. And while the current AI tools are good at writing code, they can't yet solve the problem independently. Maybe this will change, but this type of change requires another breakthrough comparable to the creation of LLMs. Moving to agent-like systems requires solving many other problems in AI, a fact acknowledged by many of the experts in the area (e.g. [see this](https://www.youtube.com/watch?v=pZybROKrj2Q) interview with Demis Hassabis).

Even if we create AI which can independently solve a prolem for a user, someone still needs to direct that AI. Software developers are ideally placed to do this. Having experience in pre-AI technology puts you in a unique position to understand the mistakes it would make, and correct them. One of the reasons for my [mindblowing experience with Cursor]({{< relref "ai-developer" >}}) was that I was able to debug and fix problems, not just write code. But that still requires a human behind the wheel who knows what to ask, how to write a prompt for the AI and think critically about the offered solution. Solving a problem through technology is still an iterative process. It requires adaptive learning in a complex domain. It sometimes requires trial and error to discover solutions. Humans are still best at these activities.

Lastly, I'm sure LLMs will become better with time. Maybe some day they will be able to do everything a software developer does today. That still doesn't mean the job of a developer would disappear. The car didn't kill the job of a driver, but changed it. It required different skills. The computer didn't kill the job of an accountant or banker. It made accountants and bankers more efficient. You could say these jobs kept their names but are fundamentally different, and you would be right. Accountants don't spend their time doing manual calculations any more. They focus on the strategy of accounting. Is that the same job? In outcomes for the user, yes. In what you do day to day - most definitely not.

It doesn't matter though, because that's always how technological progress works. It changes how humans have to behave, sometimes fundamentally. Whether you call things the same as before is irrelevant. The important thing is that we're all better off as a result. We are better off not only through being more efficient, but also through opportunities which were not there before. The car made drivers more efficient, sure. But it also enabled suburbs, larger cities, and practically served as the first product for [the assemly line](https://corporate.ford.com/articles/history/moving-assembly-line.html), which has had immeasureable value for everyone. And I'll leave it as an exercise for the reader to measure the value of the opportunity created by computers.

Developer jobs are safe; in fact GenAI may be a big boon for them. The caveat is that to benefit, you need to be open-minded. I like how someone at work recently summarised this: "AI will not take your job. But someone using it might."